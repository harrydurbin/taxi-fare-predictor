{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harry Durbin\n",
    "## CE 263-Scalable Spatial Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble.forest import RandomForestRegressor\n",
    "from sklearn import cross_validation\n",
    "\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import utm\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Taxi Fares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn = 'Taxi_Train.csv'\n",
    "predictions = np.genfromtxt(fn, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# time_input = []\n",
    "time_convert = np.zeros(shape=([len(predictions),3]))\n",
    "day = np.zeros(shape=([len(predictions),1]))\n",
    "i = 0\n",
    "with open(fn) as f: \n",
    "    for line in f: # go over data file, line by line\n",
    "        x = line.split(',') # get a list of attributes, as strings\n",
    "        # parse the time strings from %m/%d/%Y %H:%M format into seconds\n",
    "        tto = datetime.strptime(x[1], \"%m/%d/%Y %H:%M\")\n",
    "\n",
    "        dayofweek = tto.strftime('%a')\n",
    "        if dayofweek == 'Sat':\n",
    "            day[i,0] = 1\n",
    "        elif dayofweek == 'Sun':\n",
    "            day[i,0] = 1\n",
    "\n",
    "        to = (tto - tto.replace(hour=0, minute=0, second=0, microsecond=0)).total_seconds()\n",
    "        time_convert[i,0] = to\n",
    "        time_convert[i,1] = int(to/60/60)\n",
    "        time_convert[i,2] = int(to%3600/60)\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add day column to predictions array\n",
    "predictions = np.concatenate((predictions,day),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# delete row from array if fare value appears to be missing/inaccurate\n",
    "#i.e. if fare is less than $1.00, it seems unrealistic\n",
    "predictions = predictions[~(predictions[:,3]<1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cross validation\n",
    "kf = cross_validation.KFold(n=len(predictions), n_folds=10, indices=None, \n",
    "                       shuffle=False, random_state=None)\n",
    "for train_index, test_index in kf:\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    predictions_train, predictions_test = predictions[train_index], predictions[test_index]\n",
    "    \n",
    "# cross validation\n",
    "kf2 = cross_validation.KFold(n=len(time_convert), n_folds=10, indices=None, \n",
    "                       shuffle=False, random_state=None)\n",
    "for train_index, test_index in kf2:\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    time_convert_train, time_convert_test = time_convert[train_index], time_convert[test_index]  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Travel Time predictor\n",
    "class TaxiFarePredictor:\n",
    "     \n",
    "    def __init__(self, fname, TTmodel_type = 'RF', Fmodel_type = 'RF'):\n",
    "\n",
    "        self.TTmodel_type = TTmodel_type # travel time model type\n",
    "        self.Fmodel_type = Fmodel_type # fare predictor model type\n",
    "        \n",
    "        self.TTmodel = []\n",
    "        self.Fmodel = []\n",
    "        \n",
    "        # load data and process features\n",
    "        self.X, self.T, self.F = self.load_data(fname)\n",
    "    \n",
    "        # train travel time model\n",
    "        self.travel_time_model(model_type = self.TTmodel_type)\n",
    "        \n",
    "        # train fare model\n",
    "        self.fare_model(model_type = self.Fmodel_type)\n",
    "     \n",
    "    \n",
    "    def load_data(self, fname):\n",
    "        \n",
    "        #  File structure must be \n",
    "        #\n",
    "        #  0-4    ['ID', 'STARTDATE', 'ENDDATE', 'Total_amount', 'PASSENGER_NUM',\n",
    "        #  5-10   'GPS_START_LO', 'GPS_START_LA', 'GPS_END_LO', 'GPS_END_LA', 'StartTAZ1454', 'TAZ1454_end, day]\n",
    "        #\n",
    "        trips = np.genfromtxt(fname, delimiter=',')\n",
    "        features = np.zeros((trips.shape[0],15))\n",
    "        \n",
    "        \n",
    "        with open(fname,'rU') as f: \n",
    "\n",
    "            for line in f: # go over data file, line by line\n",
    "\n",
    "                l = line.split(',') # get a list of attributes, as strings\n",
    "\n",
    "                # parse the time strings from %m/%d/%Y %H:%M format into seconds\n",
    "                tto = datetime.strptime(l[1], \"%m/%d/%Y %H:%M\")\n",
    "                ttd = datetime.strptime(l[2], \"%m/%d/%Y %H:%M\")\n",
    "                \n",
    "                dayofweek = tto.strftime('%a')\n",
    "                if dayofweek == 'Sat':\n",
    "                    day = 1\n",
    "                elif dayofweek == 'Sun':\n",
    "                    day = 1\n",
    "\n",
    "                # trip duration\n",
    "                tdelta = time.mktime(ttd.timetuple()) - time.mktime(tto.timetuple())\n",
    "\n",
    "                # convert to time since midnight\n",
    "                to = (tto - tto.replace(hour=0, minute=0, second=0, microsecond=0)).total_seconds()\n",
    "                td = (ttd - ttd.replace(hour=0, minute=0, second=0, microsecond=0)).total_seconds()\n",
    "\n",
    "                # convert strings to floats\n",
    "                l[5:10] = map(lambda x: float(x), l[5:10])\n",
    "\n",
    "                # convert to meters in UTM\n",
    "                o = np.array(utm.from_latlon(l[6], l[5])[:2])\n",
    "                d = np.array(utm.from_latlon(l[8], l[7])[:2])\n",
    "\n",
    "                # euclidean distance between origin and destination\n",
    "                dist1 = cdist([o],[d])[0][0]\n",
    "                dist2 = abs(o[0]-d[0]) + abs(o[1]-d[1])\n",
    "                \n",
    "                \n",
    "                # collect all features we have computed\n",
    "                # id, fare, start time, travel time,passengers, TAZo, TAZd,end time, distance, origin, dest\n",
    "                features[int(l[0]),:15] = np.append(np.array([int(l[0]), float(l[3]), td, tdelta, \n",
    "                                                              float(l[4]), float(l[9]), float(l[10]),\n",
    "                                                              to, dist1,dist2,day]), np.append(o, d))\n",
    "\n",
    "#the following code applies when data is being trained with cross validation\n",
    "# remove if not bothering to train\n",
    "########################################################################################       \n",
    "        # delete row from array if fare data missing/inaccurate\n",
    "        features = features[~(features[:,1]<1.0)]                       \n",
    "                \n",
    "        # cross validation - comment out after parameters determined\n",
    "        kf = cross_validation.KFold(n=len(features), n_folds=10, indices=None, \n",
    "                               shuffle=False, random_state=None)\n",
    "        for train_index, test_index in kf:\n",
    "        #     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "            features_train, features_test = features[train_index], features[test_index]\n",
    "\n",
    "        # return X, travel time, fare          \n",
    "        return features_train[:,4:], features_train[:,3], features_train[:,1]   \n",
    "\n",
    "########################################################################################\n",
    "#add this code if data is NOT being trained with cross validation\n",
    "#  #       return X, travel time, fare          \n",
    "#         return features[:,4:], features[:,3], features[:,1]   \n",
    "\n",
    "########################################################################################  \n",
    "    \n",
    "    def travel_time_model(self, model_type='RF'):\n",
    "    \n",
    "        if model_type == 'RF':\n",
    "            self.TTmodel = RandomForestRegressor(random_state=0, n_estimators=10, max_depth=10)\n",
    "            self.TTmodel.fit(self.X, self.T)           \n",
    "        elif model_type == 'DT':\n",
    "            self.TTmodel = DecisionTreeRegressor(max_depth=100)\n",
    "            self.TTmodel.fit(self.X, self.T)           \n",
    "        else:\n",
    "            print 'Unknown model type for travel times predictor.'            \n",
    "    \n",
    "    def travel_time(self, Xq):\n",
    "    \n",
    "        return self.TTmodel.predict(Xq)\n",
    "        \n",
    "    def fare_model(self, model_type='RF'):\n",
    "        \n",
    "        T = self.T\n",
    "        X = np.hstack( (self.X, np.array([self.T]).T ))\n",
    "        \n",
    "        if model_type == 'RF':\n",
    "            self.Fmodel = RandomForestRegressor(random_state=0, n_estimators=10, max_depth=10)\n",
    "            self.Fmodel.fit(X, self.F)  \n",
    "        elif model_type == 'DT':\n",
    "            self.Fmodel = DecisionTreeRegressor(max_depth=100)\n",
    "            self.Fmodel.fit(X, self.F)          \n",
    "        else:\n",
    "            print 'Unknown model type for trip fare predictor.'\n",
    "    \n",
    "    \n",
    "    def fare(self, Xq):\n",
    "        \n",
    "        return self.Fmodel.predict(Xq)\n",
    "\n",
    "    \n",
    "    # can take (lat, lon) pairs or address as text, via geolocator geocoding\n",
    "    # origin, destination, start time, number passenger, TAZ origin, TAZ dest\n",
    "    def TaxiFare(self, orig, dest, tstart='0:00', npax=1, TAZo=0, TAZd=0, day=0):\n",
    "        \n",
    "        if not isinstance(orig, basestring): \n",
    "            if not isinstance(dest, basestring): \n",
    "                \n",
    "                o = np.array(utm.from_latlon(orig[1], orig[0])[:2])\n",
    "                d = np.array(utm.from_latlon(dest[1], dest[0])[:2])\n",
    "               \n",
    "        else:\n",
    "            \n",
    "            try:\n",
    "                geolocator = Nominatim()\n",
    "\n",
    "                origin = geolocator.geocode(orig)\n",
    "                destination = geolocator.geocode(dest)\n",
    "    \n",
    "                o = np.array(utm.from_latlon(origin.latitude, origin.longitude)[:2])\n",
    "                d = np.array(utm.from_latlon(destination.latitude, destination.longitude)[:2])\n",
    "            \n",
    "            except:\n",
    "                \n",
    "                print 'Geocoding error. Try providing WGS84 coordinates instead.'\n",
    "                \n",
    "                return 0\n",
    "            \n",
    "        # euclidean distance between origin and destination\n",
    "        dist1 = cdist([o],[d])[0][0]\n",
    "        dist2 = abs(o[0]-d[0]) + abs(o[1]-d[1])\n",
    "\n",
    "        \n",
    "        #print str(depart_s)\n",
    "        temp = datetime.strptime('09/01/2012 '+ str(tstart), \"%m/%d/%Y %H:%M\")\n",
    "        depart = (temp - temp.replace(hour=0, minute=0, second=0, microsecond=0)).total_seconds()\n",
    "       \n",
    "        # features for travel time prediction\n",
    "        xq = np.append(np.array([float(npax), float(TAZo), float(TAZd), depart, dist1,dist2,day]), np.append(o, d))\n",
    "                \n",
    "        # predict travel time\n",
    "        tt = self.travel_time(xq)\n",
    "        \n",
    "        # predict fare\n",
    "        f = self.fare(np.append(xq, tt))\n",
    "        \n",
    "        return f[0]  # tt[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TFP = TaxiFarePredictor('Taxi_Train.csv', TTmodel_type = 'RF', Fmodel_type = 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting fares for kfolded test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_input = []\n",
    "for row in range(len(time_convert_test)):\n",
    "    time_input.append(str(int(time_convert_test[row,1])) + ':' + str(int(time_convert_test[row,2])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  0-4    ['ID', 'STARTDATE', 'ENDDATE', 'Total_amount', 'PASSENGER_NUM',\n",
    "#  5-10   'GPS_START_LO', 'GPS_START_LA', 'GPS_END_LO', 'GPS_END_LA', 'StartTAZ1454', 'TAZ1454_end]\n",
    "coords_start = predictions_test[:,5:7]\n",
    "coords_end = predictions_test[:,7:9]\n",
    "time_start = time_input[:]\n",
    "passengers = predictions_test[:,4]\n",
    "taz_start = predictions_test[:,9]\n",
    "taz_end = predictions_test[:,10]\n",
    "day = predictions_test[:,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_fares = []\n",
    "cv = []\n",
    "\n",
    "for row in range(len(predictions_test)):\n",
    "    predicted_fares.append(TFP.TaxiFare((coords_start[row,0],coords_start[row,1]), (coords_end[row,0],coords_end[row,1]),\n",
    "                   time_start[row], passengers[row], taz_start[row], taz_end[row],day[row]))\n",
    "    cv.append(((predicted_fares[row] - predictions_test[row,3])**2)**0.5)\n",
    "#     if row%200==0:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ 2.37\n"
     ]
    }
   ],
   "source": [
    "avg_error = np.mean(cv)\n",
    "print '$',format(avg_error, '.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ 42.00 $ 47.22\n",
      "$ 13.40 $ 12.60\n",
      "$ 13.95 $ 16.04\n",
      "$ 11.00 $ 10.62\n",
      "$ 21.65 $ 12.21\n",
      "$ 9.30 $ 8.84\n",
      "$ 21.10 $ 13.42\n",
      "$ 6.25 $ 6.61\n",
      "$ 8.45 $ 9.60\n",
      "$ 6.25 $ 7.70\n"
     ]
    }
   ],
   "source": [
    "actual_fares = predictions_test[:,3]\n",
    "for row in range(10):\n",
    "    print '$',format(actual_fares[row],'.2f'), '$',format(predicted_fares[row], '.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### running actual test data in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_file = 'Taxi_Query.csv'\n",
    "time_input_testset = []\n",
    "day = []\n",
    "with open(test_file) as fn: \n",
    "    for line in fn: # go over data file, line by line\n",
    "        x = line.split(',') # get a list of attributes, as strings\n",
    "        # parse the time strings from %m/%d/%Y %H:%M format into seconds\n",
    "        tto = datetime.strptime(x[1], \"%m/%d/%Y %H:%M\")\n",
    "        to = (tto - tto.replace(hour=0, minute=0, second=0, microsecond=0)).total_seconds()\n",
    "        h = int(to/60/60) \n",
    "        m = int(to%3600/60)\n",
    "        time_input_testset.append(str(h) + ':' + str(m))\n",
    "        dayofweek = tto.strftime('%a')\n",
    "        if dayofweek == 'Sat':\n",
    "            dayx = 1\n",
    "        elif dayofweek == 'Sun':\n",
    "            dayx = 1\n",
    "        else:\n",
    "            dayx=0\n",
    "        day.append(dayx)\n",
    "            \n",
    "\n",
    "#  0-4    ['ID', 'STARTDATE', 'ENDDATE', 'Total_amount', 'PASSENGER_NUM',\n",
    "#  5-10   'GPS_START_LO', 'GPS_START_LA', 'GPS_END_LO', 'GPS_END_LA', 'StartTAZ1454', 'TAZ1454_end]\n",
    "predictions_testset = np.genfromtxt(test_file, delimiter=',')       \n",
    "coords_start = predictions_testset[:,5:7]\n",
    "coords_end = predictions_testset[:,7:9]\n",
    "time_start = time_input_testset[:]\n",
    "passengers = predictions_testset[:,4]\n",
    "taz_start = predictions_testset[:,9]\n",
    "taz_end = predictions_testset[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_fares_testset = []\n",
    "\n",
    "for row in range(len(predictions_testset)):\n",
    "    predicted_fares_testset.append(TFP.TaxiFare((coords_start[row,0],coords_start[row,1]), (coords_end[row,0],coords_end[row,1]),\n",
    "                   time_start[row], passengers[row], taz_start[row], taz_end[row],day[row])) \n",
    "#     if row%100==0:\n",
    "#         print row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ 52.90\n",
      "$ 7.70\n",
      "$ 15.09\n",
      "$ 8.40\n",
      "$ 48.02\n",
      "$ 8.74\n",
      "$ 10.26\n",
      "$ 12.12\n",
      "$ 11.17\n",
      "$ 10.43\n"
     ]
    }
   ],
   "source": [
    "for row in range(10):\n",
    "    print '$',format(predicted_fares_testset[row], '.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### writing predictions to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.zeros(shape=[(len(predictions_testset)),2])\n",
    "a[:,0] = predictions_testset[:,0] \n",
    "a[:,1] = predicted_fares_testset[:]\n",
    "\n",
    "np.savetxt(\"predictions2.csv\", a, fmt='%.2f', delimiter=\",\", \n",
    "           header= 'id,fare_predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver Advisory System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_file = 'Taxi_Train.csv'\n",
    "time_input_testset = []\n",
    "to = []\n",
    "with open(test_file) as fn: \n",
    "    for line in fn: # go over data file, line by line\n",
    "        x = line.split(',') # get a list of attributes, as strings\n",
    "        # parse the time strings from %m/%d/%Y %H:%M format into seconds\n",
    "        tto = datetime.strptime(x[1], \"%m/%d/%Y %H:%M\")\n",
    "        to.append((tto - tto.replace(hour=0, minute=0, second=0, microsecond=0)).total_seconds())\n",
    "\n",
    "#  0-4    ['ID', 'STARTDATE', 'ENDDATE', 'Total_amount', 'PASSENGER_NUM',\n",
    "#  5-10   'GPS_START_LO', 'GPS_START_LA', 'GPS_END_LO', 'GPS_END_LA', 'StartTAZ1454', 'TAZ1454_end]\n",
    "predictions_testset = np.genfromtxt(test_file, delimiter=',')       \n",
    "coords_start = predictions_testset[:,5:7]\n",
    "coords_end = predictions_testset[:,7:9]\n",
    "time_start = to[:]\n",
    "passengers = predictions_testset[:,4]\n",
    "taz_start = predictions_testset[:,9]\n",
    "taz_end = predictions_testset[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226 distinct TAZs at start\n",
      "581 distinct TAZs at end\n"
     ]
    }
   ],
   "source": [
    "u = set(taz_start)\n",
    "y = set(taz_end)\n",
    "u = list(u)\n",
    "y = list(y)\n",
    "print len(u) , 'distinct TAZs at start'\n",
    "print len(y) , 'distinct TAZs at end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAZ = 239.0 was the most popular origin with 3696.0 rides.\n",
      "TAZ = 239.0 was the most popular destination with 2813.0 rides.\n"
     ]
    }
   ],
   "source": [
    "taxi_counts_o = np.zeros(shape=[(len(u)),2])\n",
    "for i in range(len(u)):\n",
    "    taxi_counts_o[i,0] = int(u[i])\n",
    "    for j in range(len(taz_start)):\n",
    "        if taz_start[j]==taxi_counts_o[i,0]:\n",
    "            taxi_counts_o[i,1] += 1   \n",
    "\n",
    "z = taxi_counts_o[taxi_counts_o[:,1].argsort()]\n",
    "print 'TAZ =', z[len(u)-1,0] , 'was the most popular origin with' , z[len(u)-1,1] , 'rides.'\n",
    "\n",
    "taxi_counts_d = np.zeros(shape=[(len(y)),2])\n",
    "for i in range(len(y)):\n",
    "    taxi_counts_d[i,0] = int(y[i])\n",
    "    for j in range(len(taz_end)):\n",
    "        if taz_end[j]==taxi_counts_d[i,0]:\n",
    "            taxi_counts_d[i,1] += 1   \n",
    "\n",
    "z = taxi_counts_d[taxi_counts_d[:,1].argsort()]\n",
    "print 'TAZ =', z[len(y)-1,0] , 'was the most popular destination with' , z[len(y)-1,1] , 'rides.'\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
